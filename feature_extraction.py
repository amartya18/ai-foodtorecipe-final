# -*- coding: utf-8 -*-
"""feature_extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DQB0M6JjsxNTx5DZ18UOaLJf9-Jooow3
"""

from google.colab import auth
auth.authenticate_user()
project_id = 'colab-bucket'
!gcloud config set project {project_id}

!  curl https://storage.googleapis.com/gcping-release/gcping_linux_amd64_0.0.3 > gcping && chmod +x gcping
! ./gcping

# to mount gcs to colab (THIS SAVED MY LIFE DAMNNNNNNNN)
!echo "deb http://packages.cloud.google.com/apt gcsfuse-bionic main" > /etc/apt/sources.list.d/gcsfuse.list
!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
!apt -qq update
!apt -qq install gcsfuse

# mount the folder
bucket_name = 'colab-bucket-recipe1m-train-2'
!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 {bucket_name} /content/gcstorage/

! pip install FALCONN

import keras
from keras.preprocessing import image
from keras.models import Model, load_model
from keras.applications.imagenet_utils import preprocess_input as preprocess_input_vgg

import os
from tqdm import tqdm

import random
import numpy as np
import pandas as pd
import _pickle as pickle
from pprint import pprint

import tables

def get_image_vgg(path):
    img = image.load_img(path, target_size=model.input_shape[1:3])
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input_vgg(x)
    return img, x

model = keras.applications.VGG16(weights='imagenet', include_top=True)

feat_extractor = Model(inputs=model.input, outputs=model.get_layer("fc2").output)
img, x = get_image_vgg('/content/gcstorage/train2/0f047b27af.jpg')
feat = feat_extractor.predict(x)
print(len(feat[0]))

path = "/content/gcstorage/train1"
images = os.listdir(path)

data_shape = (0, 4096)
img_dtype = tables.Float32Atom()

hdf5_path = '/content/gcstorage/vgg16_bottleneck_features7.hdf5'

hdf5_file = tables.open_file(hdf5_path, mode='w')
img_error = []

hdf5_file.create_array(hdf5_file.root, 'img_paths', images)
features = hdf5_file.create_earray(hdf5_file.root, 'img_features', img_dtype, shape=data_shape)

for image_path in tqdm(images):
  try:
    img, x = get_image_vgg('/content/gcstorage/train1/'+image_path);
    feat = feat_extractor.predict(x)[0]
    features.append(feat[None])
  except:
    img_error.append(image_path)
    
hdf5_file.close()
error = np.asarray(img_error)
np.savetxt('/content/gcstorage/vgg16_img_error.csv', error, delimiter=',')

print(error)
np.save('/content/gcstorage/vgg16_img_error.csv', error)

# hdf5_path = '/content/gcstorage/vgg16_bottleneck_features6.hdf5'

hdf5_file_temp = tables.open_file(hdf5_path, mode='r')
features = hdf5_file_temp.root.img_features
images = hdf5_file_temp.root.img_paths

!pip install annoy

from annoy import AnnoyIndex

# nearest neighbor
def get_closest_images_fast(query_features, num_results=15):
    return falconn.find_k_nearest_neighbors(query_features, num_results)
  
def get_closest_images_fast_annoy(query_features, num_results=6):
    return t.get_nns_by_vector(query_features, num_results)

# print(model.input_shape[1:3])

query_image, x = get_image_vgg('/content/224cchips.jpg');
query_features = feat_extractor.predict(x)[0]

t = AnnoyIndex(4096)
for i, v in enumerate(tqdm(features[:7901])):
  t.add_item(i, v)

t.build(32)
t.save('/content/gcstorage/annoy_ann/test1_7901.ann')

def get_closest_images_fast_annoy(query_features, num_results=6):
    return t.get_nns_by_vector(query_features, num_results)

idx_closest = get_closest_images_fast_annoy(query_features)
print(idx_closest)

print(images[4543])

import pandas as pd

df = pd.read_csv('/content/gcstorage/layers/img_to_recipe.csv')

test_image = (df[df['image_id'] == '0ab95c7853.jpg']['image_url'].values)
print(test_image)

print(type(images))

np_images = np.array(images)
np_images_str = np_images.astype(str)

# print(np_images_str)
# print(error)

clean_images = []

for i in np_images_str:
  if i not in error:
    clean_images.append(i)

print(len(images))
print(len(clean_images))

print(len(features[:]))
print(type(features[:]))

from tqdm import tqdm
from IPython.display import clear_output

x = AnnoyIndex(4096)
for i, v in enumerate(tqdm(features[:])):
  x.add_item(i, v)
  clear_output(wait=True)

x.build(32)
x.save('/content/gcstorage/annoy_ann/test2_all.ann')

def get_closest_images_fast_annoy(query_features, num_results=6):
  return x.get_nns_by_vector(query_features, num_results)

idx_closest = get_closest_images_fast_annoy(query_features)
print(idx_closest)

print(clean_images[108189])

df = pd.read_csv('/content/gcstorage/layers/img_to_recipe.csv')

print(df)
# test_image = (df[df['image_id'] == '0ab95c7853.jpg']['image_url'].values)
# print(test_image)

