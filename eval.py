# -*- coding: utf-8 -*-
"""eval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sBZf7khDt3UkvSTVGmZHh-TbheZhRJwG
"""

from google.colab import auth
auth.authenticate_user()
project_id = 'colab-bucket'
!gcloud config set project {project_id}

!  curl https://storage.googleapis.com/gcping-release/gcping_linux_amd64_0.0.3 > gcping && chmod +x gcping
! ./gcping

# to mount gcs to colab (THIS SAVED MY LIFE)
!echo "deb http://packages.cloud.google.com/apt gcsfuse-bionic main" > /etc/apt/sources.list.d/gcsfuse.list
!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
!apt -qq update
!apt -qq install gcsfuse

# mount the folder
bucket_name = 'colab-bucket-recipe1m-train-2'
!mkdir gcstorage
!gcsfuse --implicit-dirs --limit-bytes-per-sec -1 --limit-ops-per-sec -1 {bucket_name} /content/gcstorage/

import keras
from keras.preprocessing import image
from keras.models import Model, load_model
from keras.applications.imagenet_utils import preprocess_input as preprocess_input_vgg

import os
from tqdm import tqdm

import random
import numpy as np
import pandas as pd
import _pickle as pickle
from pprint import pprint

import tables
from IPython.display import clear_output

layer1 = pd.read_csv('/content/gcstorage/layers/layer1m.csv')
layer2 = pd.read_json('/content/gcstorage/layers/layer2.json')

model = keras.applications.VGG16(weights='imagenet', include_top=True)
feat_extractor = Model(inputs=model.input, outputs=model.get_layer("fc2").output)

def img_encode(filepath):
  img_width, img_height = 254, 254
  try:
    img = image.load_img(filepath, target_size=(img_width, img_height))
  except:
    return False, False
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  x = preprocess_input_vgg(x)
  return img, x

considered_recipes = 0
next_prog = .01

out = False
num_sims = 0
similarity_sum = 0
# print(layer2[len(layer2['images']) > 1])
for i in range(1000):
  if i / float(1000) >= next_prog:
    print(str(next_prog * 100) + '%')
    clear_output(wait=True)
    next_prog += 0.01
  num_imgs = min(len(layer2['images'][i]), 5)
  recipe_id = layer2['id'][i]
  layer1_idx = layer1['id'][layer1['id'] == recipe_id].index[0]
  directory = layer1['partition'][layer1_idx]
  if (num_imgs == 1): continue
  considered_recipes += 1

  encodings = {}
  for j in range(num_imgs):
    out = False
    file1 = layer2['images'][i][j]['id']
    file1 = '/content/gsctorage/train1/' + file1
    enc1 = None
    if file1 in encodings:
      enc1 = encodings[file1]
    else:
      query_image, x = img_encode(file1);
      # if does not exist break
      if(query_image == False):
        break
      enc1 = feat_extractor.predict(x)[0]
      encodings[file1] = enc1

    for j in range(i + 1, num_imgs):
      file2 = layer2['images'][recipe_i][j]['id']
      file2 = '/content/gsctorage/train1/' + file2
      enc2 = None
      if file2 in encodings:
        enc2 = encodings[file2]
      else:
        query_image, x = img_encode(file2)
        enc1 = feat_extractor.predict(x)[0]
        if(query_image == False):
          out = True
          break
      num_sims += 1
      similarity_sum += linal.norm(enc1 - enc2)
    if(out == True):
      break

print('Average similarity: ' + str(similarity_sum / num_sims))

print(considered_recipes)

